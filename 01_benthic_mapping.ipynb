{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benthic Habitat Mapping with Hyperspectral Remote Sensing\n",
    "\n",
    "## Mapping the Seafloor from Space Using Planet Tanager Data\n",
    "\n",
    "---\n",
    "\n",
    "**The Science Question:**\n",
    "\n",
    "> *\"Can we map what's on the seafloor in shallow coastal waters using hyperspectral imagery - and does having 400+ spectral bands help compared to traditional multispectral sensors?\"*\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we'll explore an exciting application of hyperspectral remote sensing: **seeing through water to map the seafloor**.\n",
    "\n",
    "In clear, shallow coastal waters, sunlight penetrates to the bottom, reflects off the substrate (sand, seagrass, coral, algae), and travels back up through the water column to a satellite sensor. Different bottom types have distinct spectral signatures - unique \"fingerprints\" of how they reflect light at different wavelengths.\n",
    "\n",
    "With traditional **multispectral** sensors like Landsat or Sentinel-2 (3-10 broad bands), these signatures can look frustratingly similar. But with **hyperspectral** data from Planet's Tanager satellite (426 narrow bands), we can detect subtle absorption features that distinguish between different habitats.\n",
    "\n",
    "### Why Does This Matter?\n",
    "\n",
    "- **Seagrass meadows** are one of the most effective carbon sinks on Earth, storing carbon 35x faster than tropical rainforests\n",
    "- **Coastal habitat monitoring** is critical for fisheries management and biodiversity conservation\n",
    "- **Climate change** and human activities are rapidly altering shallow marine ecosystems\n",
    "- Traditional field surveys are expensive, time-consuming, and can only cover small areas\n",
    "\n",
    "Satellite-based mapping offers a scalable solution - but only if we can accurately distinguish between different habitat types.\n",
    "\n",
    "### From Raw Data to Usable Information\n",
    "\n",
    "Satellite data doesn't come ready to use. The raw measurements include contributions from:\n",
    "\n",
    "- **The atmosphere** — scattering and absorption by gases, aerosols, and water vapor\n",
    "- **Sun-sensor geometry** — the angles of illumination and viewing affect apparent brightness\n",
    "- **The water surface** — sun glint and reflection at the air-water interface\n",
    "- **The water column** — absorption and scattering by water itself\n",
    "- **The seafloor** — what we actually want to measure!\n",
    "\n",
    "The Tanager data we downloaded is **top-of-atmosphere (TOA) radiance** — the total light that reached the sensor. To extract meaningful information about the seafloor, we need **atmospheric correction** to remove the atmospheric (and for water, surface and water column) contributions.\n",
    "\n",
    "The result is **remote sensing reflectance (Rrs)** — a physically meaningful quantity representing light leaving the water. This is what Acolite will compute for us.\n",
    "\n",
    "For water applications, atmospheric correction is especially critical. When a satellite looks at the ocean, **85-95% of the light it detects never even touched the water** — it's sunlight scattered back by the atmosphere. The actual signal from the water (and seafloor) is just 5-15% of the total. Without correction, we'd be trying to see through overwhelming atmospheric \"noise.\"\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. What hyperspectral data is and why it matters for coastal applications\n",
    "2. How to load and visualize Planet Tanager data using HyperCoast\n",
    "3. How to extract and interpret spectral signatures from different benthic types\n",
    "4. Why atmospheric correction is critical for water applications\n",
    "5. How to classify benthic habitats using spectral data\n",
    "6. The quantitative advantage of hyperspectral over multispectral data\n",
    "\n",
    "---\n",
    "\n",
    "**Study Area:** Abu Dhabi, UAE - Persian Gulf coast  \n",
    "**Why this location:** Crystal-clear shallow waters, distinct benthic types (sand, seagrass beds, darker substrates), minimal river input means low turbidity\n",
    "\n",
    "**Estimated time:** 15-20 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Background: Hyperspectral vs. Multispectral Remote Sensing\n",
    "\n",
    "### What's the Difference?\n",
    "\n",
    "Imagine you're trying to identify different types of fabric by their color:\n",
    "\n",
    "- **Multispectral** is like seeing in **RGB** - you can tell red from blue, but two shades of burgundy might look identical\n",
    "- **Hyperspectral** is like seeing in **400+ colors** - suddenly you can distinguish between cotton burgundy, silk burgundy, and wool burgundy\n",
    "\n",
    "| Feature | Multispectral (e.g., Sentinel-2) | Hyperspectral (Tanager) |\n",
    "|---------|----------------------------------|-------------------------|\n",
    "| Number of bands | ~10 | 426 |\n",
    "| Band width | Broad (~20-100nm) | Narrow (~5nm) |\n",
    "| Spectral range | Visible + some NIR/SWIR | 380-2500nm (continuous) |\n",
    "| Spatial resolution | 10-60m | ~30m |\n",
    "| Absorption features | Missed or averaged out | Captured precisely |\n",
    "\n",
    "### Why Does This Matter for Underwater Mapping?\n",
    "\n",
    "Different materials absorb light at specific wavelengths:\n",
    "- **Chlorophyll** (in seagrass and algae) absorbs strongly around **675nm**\n",
    "- **Water** absorbs increasingly in the **red and near-infrared**\n",
    "- **Sand** reflects broadly across the visible spectrum\n",
    "\n",
    "With 426 narrow bands, hyperspectral sensors can detect these subtle absorption features that get smoothed out in broad multispectral bands.\n",
    "\n",
    "### Planet Tanager Mission\n",
    "\n",
    "Planet's Tanager satellite, launched in **August 2024**, represents a new generation of commercial hyperspectral imaging:\n",
    "\n",
    "- **426 spectral bands** from 380-2500nm (VSWIR range)\n",
    "- **~5nm spectral resolution** - narrow enough to capture absorption features\n",
    "- **~30m ground sample distance** - suitable for habitat-scale mapping\n",
    "- **Global coverage** - enabling consistent monitoring worldwide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Setup and Data Access\n",
    "\n",
    "Let's start by importing the libraries we'll need and downloading our study scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:44:58.656919Z",
     "iopub.status.busy": "2026-01-18T03:44:58.656324Z",
     "iopub.status.idle": "2026-01-18T03:44:58.663858Z",
     "shell.execute_reply": "2026-01-18T03:44:58.661913Z",
     "shell.execute_reply.started": "2026-01-18T03:44:58.656876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperCoast version: 0.18.0\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import hypercoast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# For classification\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configure proxy for JupyterHub map rendering\n",
    "# This is needed for interactive maps to display on remote Jupyter servers\n",
    "os.environ['LOCALTILESERVER_CLIENT_PREFIX'] = 'proxy/{port}'\n",
    "\n",
    "# Suppress some warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "print(f\"HyperCoast version: {hypercoast.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Tanager Scene\n",
    "\n",
    "We'll use a scene from Abu Dhabi, UAE captured on May 11, 2025. This scene shows the shallow coastal waters of the Persian Gulf, which are known for their clarity and diverse benthic habitats.\n",
    "\n",
    "The data is stored as an **HDF5 file** containing top-of-atmosphere (TOA) radiance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:44:58.745890Z",
     "iopub.status.busy": "2026-01-18T03:44:58.745469Z",
     "iopub.status.idle": "2026-01-18T03:44:58.754489Z",
     "shell.execute_reply": "2026-01-18T03:44:58.752030Z",
     "shell.execute_reply.started": "2026-01-18T03:44:58.745856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Tanager scene... this may take a few minutes.\n",
      "20250511_074311_00_4001_basic_radiance.h5 already exists. Skip downloading. Set overwrite=True to overwrite.\n",
      "\n",
      "Download complete! File saved to: /home/jupyter/edc-tanager-demos/20250511_074311_00_4001_basic_radiance.h5\n"
     ]
    }
   ],
   "source": [
    "# Abu Dhabi scene - clear shallow waters with visible benthic features\n",
    "url = \"https://storage.googleapis.com/open-cogs/planet-stac/release1-basic-radiance/20250511_074311_00_4001_basic_radiance.h5\"\n",
    "\n",
    "# Download the file (this may take a minute - the file is ~2GB)\n",
    "print(\"Downloading Tanager scene... this may take a few minutes.\")\n",
    "filepath = hypercoast.download_file(url)\n",
    "print(f\"\\nDownload complete! File saved to: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Tanager Data\n",
    "\n",
    "HyperCoast provides a convenient function to read Tanager HDF5 files into an xarray Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:44:58.757065Z",
     "iopub.status.busy": "2026-01-18T03:44:58.756658Z",
     "iopub.status.idle": "2026-01-18T03:45:03.592361Z",
     "shell.execute_reply": "2026-01-18T03:45:03.590642Z",
     "shell.execute_reply.started": "2026-01-18T03:44:58.757025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset overview:\n",
      "<xarray.Dataset> Size: 651MB\n",
      "Dimensions:       (wavelength: 426, y: 624, x: 607)\n",
      "Coordinates:\n",
      "  * wavelength    (wavelength) float64 3kB 380.0 385.0 ... 2.495e+03 2.5e+03\n",
      "    latitude      (y, x) float64 3MB 24.19 24.19 24.19 ... 23.99 23.99 23.99\n",
      "    longitude     (y, x) float64 3MB 53.67 53.67 53.67 ... 53.86 53.86 53.86\n",
      "Dimensions without coordinates: y, x\n",
      "Data variables:\n",
      "    toa_radiance  (wavelength, y, x) float32 645MB 109.2 99.28 ... 0.1329 0.1175\n",
      "Attributes:\n",
      "    source:   Planet Tanager HDF5\n",
      "    units:    radiance\n"
     ]
    }
   ],
   "source": [
    "# Read the Tanager data directly from HDF5\n",
    "# Note: We read directly from the HDF5 file because the STAC metadata format \n",
    "# has recently changed and hypercoast.read_tanager() may encounter issues.\n",
    "\n",
    "import h5py\n",
    "\n",
    "def read_tanager_direct(filepath):\n",
    "    \"\"\"\n",
    "    Read Tanager HDF5 file directly and construct wavelength array.\n",
    "    \n",
    "    Tanager has 426 spectral bands spanning ~380-2500nm (VSWIR range).\n",
    "    \"\"\"\n",
    "    with h5py.File(filepath, 'r') as f:\n",
    "        # Read the radiance data\n",
    "        data = f[\"HDFEOS/SWATHS/HYP/Data Fields/toa_radiance\"][()]\n",
    "        lat = f[\"HDFEOS/SWATHS/HYP/Geolocation Fields/Latitude\"][()]\n",
    "        lon = f[\"HDFEOS/SWATHS/HYP/Geolocation Fields/Longitude\"][()]\n",
    "    \n",
    "    # Construct wavelength array based on Tanager specs\n",
    "    # 426 bands from ~380nm to ~2500nm\n",
    "    n_bands = data.shape[0]\n",
    "    wavelengths = np.linspace(380, 2500, n_bands)\n",
    "    \n",
    "    # Create xarray Dataset\n",
    "    ds = xr.Dataset(\n",
    "        data_vars={\n",
    "            \"toa_radiance\": ((\"wavelength\", \"y\", \"x\"), data)\n",
    "        },\n",
    "        coords={\n",
    "            \"wavelength\": wavelengths,\n",
    "            \"latitude\": ((\"y\", \"x\"), lat),\n",
    "            \"longitude\": ((\"y\", \"x\"), lon),\n",
    "        },\n",
    "        attrs={\n",
    "            \"source\": \"Planet Tanager HDF5\",\n",
    "            \"units\": \"radiance\",\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# Read the data\n",
    "dataset = read_tanager_direct(filepath)\n",
    "\n",
    "# Let's explore what we have\n",
    "print(\"Dataset overview:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:03.594193Z",
     "iopub.status.busy": "2026-01-18T03:45:03.593778Z",
     "iopub.status.idle": "2026-01-18T03:45:03.602332Z",
     "shell.execute_reply": "2026-01-18T03:45:03.600515Z",
     "shell.execute_reply.started": "2026-01-18T03:45:03.594147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spectral bands: 426\n",
      "Wavelength range: 380.0 - 2500.0 nm\n",
      "Average band width: 4.99 nm\n"
     ]
    }
   ],
   "source": [
    "# Check the wavelengths available\n",
    "if 'wavelength' in dataset.coords:\n",
    "    wavelengths = dataset.coords['wavelength'].values\n",
    "    print(f\"Number of spectral bands: {len(wavelengths)}\")\n",
    "    print(f\"Wavelength range: {wavelengths.min():.1f} - {wavelengths.max():.1f} nm\")\n",
    "    print(f\"Average band width: {np.mean(np.diff(wavelengths)):.2f} nm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key things to note:**\n",
    "- The data contains **top-of-atmosphere (TOA) radiance** - the raw energy measured by the sensor\n",
    "- We have **426 spectral bands** spanning the visible to shortwave infrared\n",
    "- The data is **not gridded** to a regular coordinate system (HyperCoast handles the interpolation for visualization)\n",
    "- Later, we'll need to perform **atmospheric correction** to convert this to surface reflectance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Initial Visualization\n",
    "\n",
    "Let's create an interactive map to explore our scene. We'll select three bands to create a \"natural color\" composite similar to what our eyes would see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:03.603664Z",
     "iopub.status.busy": "2026-01-18T03:45:03.603380Z",
     "iopub.status.idle": "2026-01-18T03:45:06.688912Z",
     "shell.execute_reply": "2026-01-18T03:45:06.687210Z",
     "shell.execute_reply.started": "2026-01-18T03:45:03.603637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3901f3d276af40ed8c93c56d2737df7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[24.0911165, 53.7631495], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title…"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an interactive map\n",
    "m = hypercoast.Map()\n",
    "\n",
    "# Add the Tanager data using wavelengths for RGB display\n",
    "# Red ~650nm, Green ~550nm, Blue ~450nm\n",
    "m.add_tanager(\n",
    "    dataset, \n",
    "    wavelengths=[650, 550, 450],  # Specify wavelengths directly for RGB\n",
    "    vmin=0, \n",
    "    vmax=120,  # Adjust these values if the image appears too dark or bright\n",
    "    layer_name=\"Tanager RGB\"\n",
    ")\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore the scene!**\n",
    "\n",
    "Take a moment to zoom and pan around. Notice:\n",
    "- The **coastline** separating land from water\n",
    "- **Shallow areas** where you can see the bottom (lighter blues/greens)\n",
    "- **Deeper areas** that appear darker blue\n",
    "- **Different bottom types** - can you spot areas that look different from each other?\n",
    "\n",
    "### Understanding Band/Wavelength Selection\n",
    "\n",
    "With 426 bands to choose from, selecting which three to visualize can be overwhelming. You can specify bands by **wavelength** (in nm) or by **band index**. Using wavelengths is more intuitive:\n",
    "\n",
    "| Color | Wavelength | Description |\n",
    "|-------|------------|-------------|\n",
    "| Blue | ~450nm | Visible blue light |\n",
    "| Green | ~550nm | Visible green light |\n",
    "| Red | ~650nm | Visible red light |\n",
    "| NIR | ~850nm | Near-infrared (invisible to eyes) |\n",
    "\n",
    "Let's try a false-color composite to highlight vegetation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:06.690184Z",
     "iopub.status.busy": "2026-01-18T03:45:06.689880Z",
     "iopub.status.idle": "2026-01-18T03:45:09.611158Z",
     "shell.execute_reply": "2026-01-18T03:45:09.609775Z",
     "shell.execute_reply.started": "2026-01-18T03:45:06.690155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477d7e5449594716ab3f15714b04cc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[24.0911165, 53.7631495], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title…"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False color composite: NIR, Red, Green\n",
    "# Vegetation appears bright in this combination\n",
    "m2 = hypercoast.Map()\n",
    "m2.add_tanager(\n",
    "    dataset, \n",
    "    wavelengths=[850, 650, 550],  # NIR, Red, Green\n",
    "    vmin=0, \n",
    "    vmax=120,\n",
    "    layer_name=\"False Color (NIR-R-G)\"\n",
    ")\n",
    "m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this false-color view:\n",
    "- **Vegetation on land** appears bright red/pink (high NIR reflectance)\n",
    "- **Water** appears dark (water absorbs NIR strongly)\n",
    "- Any **aquatic vegetation** in shallow water may show subtle differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Exploring Spectral Signatures (Before Atmospheric Correction)\n",
    "\n",
    "Now comes the exciting part! HyperCoast lets us **click on any pixel** and instantly see its full spectral signature - all 426 bands plotted as a curve.\n",
    "\n",
    "This is the real power of hyperspectral data: instead of just 3 color values, we get a complete spectrum for every pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:09.613363Z",
     "iopub.status.busy": "2026-01-18T03:45:09.612608Z",
     "iopub.status.idle": "2026-01-18T03:45:12.637885Z",
     "shell.execute_reply": "2026-01-18T03:45:12.635367Z",
     "shell.execute_reply.started": "2026-01-18T03:45:09.613318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb754abdd7649229ce0e1981afa6085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[24.0911165, 53.7631495], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title…"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a map with the spectral signature tool\n",
    "m3 = hypercoast.Map()\n",
    "m3.add_tanager(\n",
    "    dataset, \n",
    "    wavelengths=[650, 550, 450],  # RGB display\n",
    "    vmin=0, \n",
    "    vmax=120,\n",
    "    layer_name=\"Tanager RGB\"\n",
    ")\n",
    "\n",
    "# Add the spectral signature widget\n",
    "# This enables clicking on the map to extract and plot spectra\n",
    "m3.add(\"spectral\")\n",
    "\n",
    "m3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try These Experiments:\n",
    "\n",
    "Click on different features and observe how the spectral signatures differ:\n",
    "\n",
    "1. **Deep water** - What does the spectrum look like? (Should be low values, especially in red/NIR)\n",
    "2. **Shallow water over sand** - How does it differ from deep water?\n",
    "3. **Shallow water over darker substrate** - Maybe seagrass or algae?\n",
    "4. **Land/vegetation** - Very different signature with high NIR reflectance\n",
    "\n",
    "### What You're Seeing\n",
    "\n",
    "**Important:** These spectra show **radiance** values - the raw energy measured by the sensor. This includes:\n",
    "- Light reflected from the surface we want to study\n",
    "- Light scattered by the atmosphere (haze, aerosols)\n",
    "- Light absorbed and re-emitted by atmospheric gases\n",
    "\n",
    "Think of it like looking through a dirty window - we're seeing the scene, but the window is adding its own \"signature\" to everything we observe.\n",
    "\n",
    "**To get accurate measurements of the seafloor, we need to \"clean the window\" through atmospheric correction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Atmospheric Correction with Acolite\n",
    "\n",
    "### Why Is This Critical?\n",
    "\n",
    "When sunlight travels from space to the seafloor and back to the satellite, it passes through:\n",
    "\n",
    "1. **Atmosphere (down)** - scattered and absorbed\n",
    "2. **Water surface** - some reflected, some penetrates\n",
    "3. **Water column** - absorbed and scattered\n",
    "4. **Seafloor** - reflected based on bottom type (THIS IS WHAT WE WANT)\n",
    "5. **Water column (up)** - more absorption and scattering\n",
    "6. **Atmosphere (up)** - more scattering\n",
    "\n",
    "**Atmospheric correction removes the atmospheric contribution** so we can focus on what's actually happening at the surface and below.\n",
    "\n",
    "For water applications, this is even more critical because:\n",
    "- Water-leaving radiance is typically only **5-15%** of the total signal\n",
    "- The rest is atmospheric path radiance and surface glint\n",
    "- Small errors in atmospheric correction = large errors in water analysis\n",
    "\n",
    "### Acolite: Atmospheric Correction for Aquatic Remote Sensing\n",
    "\n",
    "[Acolite](https://github.com/acolite/acolite) is a specialized processor developed by RBINS (Royal Belgian Institute of Natural Sciences) for aquatic applications. It uses a \"dark spectrum fitting\" approach:\n",
    "\n",
    "1. Finds dark pixels (deep water) where surface reflectance should be ~0 in NIR\n",
    "2. Uses these to estimate the atmospheric contribution\n",
    "3. Subtracts the atmosphere to get surface reflectance\n",
    "4. Can also derive water quality parameters (chlorophyll, suspended matter, etc.)\n",
    "\n",
    "Let's run Acolite on our Tanager scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:12.639123Z",
     "iopub.status.busy": "2026-01-18T03:45:12.638833Z",
     "iopub.status.idle": "2026-01-18T03:45:12.644972Z",
     "shell.execute_reply": "2026-01-18T03:45:12.643769Z",
     "shell.execute_reply.started": "2026-01-18T03:45:12.639095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acolite location: /opt/acolite/acolite_py_linux\n",
      "Output directory: /home/jupyter/acolite_output\n"
     ]
    }
   ],
   "source": [
    "# Acolite is pre-installed on this system\n",
    "acolite_dir = \"/opt/acolite/acolite_py_linux\"\n",
    "\n",
    "# Set up output directory in our home folder\n",
    "out_dir = os.path.expanduser(\"~/acolite_output\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Acolite location: {acolite_dir}\")\n",
    "print(f\"Output directory: {out_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:12.646512Z",
     "iopub.status.busy": "2026-01-18T03:45:12.646259Z",
     "iopub.status.idle": "2026-01-18T03:45:13.403658Z",
     "shell.execute_reply": "2026-01-18T03:45:13.402108Z",
     "shell.execute_reply.started": "2026-01-18T03:45:12.646488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting atmospheric correction with Acolite...\n",
      "This typically takes 5-10 minutes for a full Tanager scene.\n",
      "\n",
      "============================================================\n",
      "Running ACOLITE processing - Generic Version 20231023.0\n",
      "Python - linux - 3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 11:02:03) [GCC 12.3.0]\n",
      "Platform - Linux 5.10.0-37-cloud-amd64 - x86_64 - #1 SMP Debian 5.10.247-1 (2025-12-11)\n",
      "Run ID - 20260118_034512\n",
      "Identified /home/jupyter/edc-tanager-demos/20250511_074311_00_4001_basic_radiance.h5 as None type\n",
      "/home/jupyter/edc-tanager-demos/20250511_074311_00_4001_basic_radiance.h5 not recognized.\n",
      "Not deleting extracted file as \"delete_extracted_input\" is not in settings.\n",
      "Not removing text files as \"delete_acolite_run_text_files\" is not in settings.\n",
      "Not testing output directory as \"delete_acolite_output_directory\" is not in settings.\n",
      "\n",
      "============================================================\n",
      "Atmospheric correction complete!\n"
     ]
    }
   ],
   "source": [
    "# Run atmospheric correction\n",
    "# This will take several minutes - a good time to stretch!\n",
    "\n",
    "print(\"Starting atmospheric correction with Acolite...\")\n",
    "print(\"This typically takes 5-10 minutes for a full Tanager scene.\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "hypercoast.run_acolite(\n",
    "    acolite_dir=acolite_dir,\n",
    "    input_file=filepath,\n",
    "    out_dir=out_dir,\n",
    "    l2w_parameters=\"Rrs_*\",  # Remote sensing reflectance for all bands\n",
    "    rgb_rhot=True,           # Save RGB of TOA reflectance\n",
    "    rgb_rhos=True,           # Save RGB of surface reflectance\n",
    "    map_l2w=True,            # Generate maps of water parameters\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Atmospheric correction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.405626Z",
     "iopub.status.busy": "2026-01-18T03:45:13.405298Z",
     "iopub.status.idle": "2026-01-18T03:45:13.411542Z",
     "shell.execute_reply": "2026-01-18T03:45:13.410352Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.405595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acolite output files:\n",
      "  acolite_run_20260118_032226_l1r_settings_user.txt\n",
      "  acolite_run_20260118_032226_log_file.txt\n",
      "  acolite_run_20260118_032226_settings_user.txt\n",
      "  acolite_run_20260118_034512_l1r_settings_user.txt\n",
      "  acolite_run_20260118_034512_log_file.txt\n",
      "  acolite_run_20260118_034512_settings_user.txt\n"
     ]
    }
   ],
   "source": [
    "# Let's see what Acolite produced\n",
    "print(\"Acolite output files:\")\n",
    "for f in sorted(os.listdir(out_dir)):\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Acolite Outputs\n",
    "\n",
    "Acolite produces several types of files:\n",
    "\n",
    "- **`*_L1R.nc`** - Level 1R: TOA radiance in NetCDF format\n",
    "- **`*_L2R.nc`** - Level 2R: Surface reflectance (atmosphere removed)\n",
    "- **`*_L2W.nc`** - Level 2W: Water-leaving reflectance (Rrs) and derived products\n",
    "- **`.png` files** - Quick-look RGB images at different processing levels\n",
    "\n",
    "For benthic mapping, we want the **`*_L2W.nc`** file, which contains:\n",
    "- **Rrs** (Remote sensing reflectance) - the fraction of downwelling light that is reflected upward from just below the water surface\n",
    "- This is the standard product for ocean color science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.412666Z",
     "iopub.status.busy": "2026-01-18T03:45:13.412386Z",
     "iopub.status.idle": "2026-01-18T03:45:13.421204Z",
     "shell.execute_reply": "2026-01-18T03:45:13.420104Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.412640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2W file not found - Acolite may still be processing or encountered an issue.\n",
      "Check the output directory: /home/jupyter/acolite_output\n"
     ]
    }
   ],
   "source": [
    "# Find and load the L2W file\n",
    "l2w_files = [f for f in os.listdir(out_dir) if f.endswith('_L2W.nc')]\n",
    "\n",
    "if l2w_files:\n",
    "    l2w_path = os.path.join(out_dir, l2w_files[0])\n",
    "    print(f\"Loading: {l2w_path}\")\n",
    "    \n",
    "    # Load the corrected data\n",
    "    ds_corrected = xr.open_dataset(l2w_path)\n",
    "    print(\"\\nCorrected dataset variables:\")\n",
    "    print([v for v in ds_corrected.data_vars if v.startswith('Rrs')][:10], \"... and more\")\n",
    "else:\n",
    "    print(\"L2W file not found - Acolite may still be processing or encountered an issue.\")\n",
    "    print(f\"Check the output directory: {out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Comparing Before and After Atmospheric Correction\n",
    "\n",
    "Let's visualize the difference between TOA radiance (what the sensor saw) and surface reflectance (what the surface actually looks like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.422254Z",
     "iopub.status.busy": "2026-01-18T03:45:13.421988Z",
     "iopub.status.idle": "2026-01-18T03:45:13.431191Z",
     "shell.execute_reply": "2026-01-18T03:45:13.429892Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.422228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available RGB images:\n"
     ]
    }
   ],
   "source": [
    "# Display the RGB images side by side\n",
    "from IPython.display import Image, display\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# Find RGB images\n",
    "rgb_files = [f for f in os.listdir(out_dir) if 'RGB' in f and f.endswith('.png')]\n",
    "print(\"Available RGB images:\")\n",
    "for f in rgb_files:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.432288Z",
     "iopub.status.busy": "2026-01-18T03:45:13.432034Z",
     "iopub.status.idle": "2026-01-18T03:45:13.441749Z",
     "shell.execute_reply": "2026-01-18T03:45:13.440396Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.432264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No RGB images found in output directory.\n"
     ]
    }
   ],
   "source": [
    "# Display comparison if images exist\n",
    "if rgb_files:\n",
    "    fig, axes = plt.subplots(1, min(len(rgb_files), 2), figsize=(14, 7))\n",
    "    \n",
    "    if len(rgb_files) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, fname in zip(axes, rgb_files[:2]):\n",
    "        img = plt.imread(os.path.join(out_dir, fname))\n",
    "        ax.imshow(img)\n",
    "        # Clean up the filename for title\n",
    "        title = fname.replace('_', ' ').replace('.png', '')\n",
    "        ax.set_title(title, fontsize=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No RGB images found in output directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The atmospheric correction should make the image appear:\n",
    "- **Clearer** - reduced haze effect\n",
    "- **More contrast** - better separation between features\n",
    "- **Darker water** - atmospheric path radiance removed\n",
    "\n",
    "Now the spectral signatures we extract will represent the actual surface reflectance rather than what the sensor measured through the atmosphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Spectral Signatures of Benthic Habitats\n",
    "\n",
    "Now that we have atmospherically corrected data, let's extract and compare spectral signatures from different benthic types.\n",
    "\n",
    "First, let's prepare the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.443419Z",
     "iopub.status.busy": "2026-01-18T03:45:13.443137Z",
     "iopub.status.idle": "2026-01-18T03:45:13.450851Z",
     "shell.execute_reply": "2026-01-18T03:45:13.449515Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.443394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected dataset not loaded. Please check Acolite output.\n"
     ]
    }
   ],
   "source": [
    "# Extract Rrs bands from the corrected dataset\n",
    "if 'ds_corrected' in dir():\n",
    "    # Get all Rrs variable names and their wavelengths\n",
    "    rrs_vars = [v for v in ds_corrected.data_vars if v.startswith('Rrs_')]\n",
    "    \n",
    "    # Extract wavelength from variable name (e.g., 'Rrs_443' -> 443)\n",
    "    wavelengths_rrs = []\n",
    "    for v in rrs_vars:\n",
    "        try:\n",
    "            wl = float(v.split('_')[1])\n",
    "            wavelengths_rrs.append(wl)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    wavelengths_rrs = sorted(wavelengths_rrs)\n",
    "    print(f\"Number of Rrs bands: {len(wavelengths_rrs)}\")\n",
    "    print(f\"Wavelength range: {min(wavelengths_rrs):.0f} - {max(wavelengths_rrs):.0f} nm\")\n",
    "else:\n",
    "    print(\"Corrected dataset not loaded. Please check Acolite output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.452161Z",
     "iopub.status.busy": "2026-01-18T03:45:13.451795Z",
     "iopub.status.idle": "2026-01-18T03:45:13.459532Z",
     "shell.execute_reply": "2026-01-18T03:45:13.458241Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.452120Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stack Rrs bands into a 3D array (y, x, wavelength)\n",
    "if 'ds_corrected' in dir() and len(wavelengths_rrs) > 0:\n",
    "    # Sort wavelengths and corresponding variable names\n",
    "    sorted_vars = [f'Rrs_{int(wl)}' for wl in sorted(wavelengths_rrs)]\n",
    "    sorted_vars = [v for v in sorted_vars if v in ds_corrected.data_vars]\n",
    "    \n",
    "    # Stack into a single array\n",
    "    rrs_stack = np.stack([ds_corrected[v].values for v in sorted_vars], axis=-1)\n",
    "    \n",
    "    print(f\"Rrs data shape: {rrs_stack.shape} (rows, cols, bands)\")\n",
    "    \n",
    "    # Get coordinates\n",
    "    lats = ds_corrected['lat'].values if 'lat' in ds_corrected.coords else None\n",
    "    lons = ds_corrected['lon'].values if 'lon' in ds_corrected.coords else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Sample Spectra\n",
    "\n",
    "Let's sample a few locations to see the spectral differences between benthic types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.460652Z",
     "iopub.status.busy": "2026-01-18T03:45:13.460397Z",
     "iopub.status.idle": "2026-01-18T03:45:13.468482Z",
     "shell.execute_reply": "2026-01-18T03:45:13.467063Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.460628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample locations defined. Extracting spectra...\n"
     ]
    }
   ],
   "source": [
    "def extract_spectrum(data, row, col, window=3):\n",
    "    \"\"\"\n",
    "    Extract average spectrum from a small window around a pixel.\n",
    "    Using a window reduces noise from individual pixels.\n",
    "    \"\"\"\n",
    "    half_w = window // 2\n",
    "    r_start, r_end = max(0, row-half_w), min(data.shape[0], row+half_w+1)\n",
    "    c_start, c_end = max(0, col-half_w), min(data.shape[1], col+half_w+1)\n",
    "    \n",
    "    # Extract window and compute mean, ignoring NaN values\n",
    "    window_data = data[r_start:r_end, c_start:c_end, :]\n",
    "    spectrum = np.nanmean(window_data, axis=(0, 1))\n",
    "    \n",
    "    return spectrum\n",
    "\n",
    "# Define sample locations (you may need to adjust these based on the scene)\n",
    "sample_locations = {\n",
    "    'Deep Water': (400, 200),\n",
    "    'Shallow Sand': (300, 400),\n",
    "    'Dark Substrate': (350, 350),\n",
    "    'Very Shallow': (250, 500)\n",
    "}\n",
    "\n",
    "print(\"Sample locations defined. Extracting spectra...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.469664Z",
     "iopub.status.busy": "2026-01-18T03:45:13.469370Z",
     "iopub.status.idle": "2026-01-18T03:45:13.479418Z",
     "shell.execute_reply": "2026-01-18T03:45:13.477935Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.469638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rrs data not available. Please ensure Acolite processing completed.\n"
     ]
    }
   ],
   "source": [
    "# Extract and plot spectra\n",
    "if 'rrs_stack' in dir():\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    colors = plt.cm.tab10.colors\n",
    "    wavelengths_sorted = sorted(wavelengths_rrs)\n",
    "    \n",
    "    for i, (name, (row, col)) in enumerate(sample_locations.items()):\n",
    "        row = min(row, rrs_stack.shape[0] - 1)\n",
    "        col = min(col, rrs_stack.shape[1] - 1)\n",
    "        \n",
    "        spectrum = extract_spectrum(rrs_stack, row, col)\n",
    "        \n",
    "        if not np.all(np.isnan(spectrum)):\n",
    "            ax.plot(wavelengths_sorted, spectrum, \n",
    "                    label=name, color=colors[i], linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Wavelength (nm)', fontsize=12)\n",
    "    ax.set_ylabel('Remote Sensing Reflectance (Rrs)', fontsize=12)\n",
    "    ax.set_title('Spectral Signatures of Different Benthic Types', fontsize=14)\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add key wavelength markers\n",
    "    key_wavelengths = {443: 'Blue', 550: 'Green', 675: 'Chl-a absorption', 700: 'Red edge'}\n",
    "    for wl, label in key_wavelengths.items():\n",
    "        if min(wavelengths_sorted) <= wl <= max(wavelengths_sorted):\n",
    "            ax.axvline(x=wl, color='gray', linestyle='--', alpha=0.5)\n",
    "            ax.text(wl+5, ax.get_ylim()[1]*0.9, label, fontsize=8, rotation=90)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Rrs data not available. Please ensure Acolite processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Spectra\n",
    "\n",
    "| Bottom Type | Spectral Characteristics |\n",
    "|-------------|-------------------------|\n",
    "| **Sand** | High overall reflectance, relatively flat in visible, peak in green |\n",
    "| **Seagrass** | Lower reflectance, absorption feature near 675nm (chlorophyll), possible red edge |\n",
    "| **Deep Water** | Very low reflectance (signal attenuated by water depth), blue-dominated |\n",
    "| **Algae-covered** | Variable, often shows chlorophyll absorption, may be brownish |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Benthic Habitat Classification\n",
    "\n",
    "Let's use **K-means clustering** to classify different benthic habitats based on their spectral signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.480651Z",
     "iopub.status.busy": "2026-01-18T03:45:13.480379Z",
     "iopub.status.idle": "2026-01-18T03:45:13.487132Z",
     "shell.execute_reply": "2026-01-18T03:45:13.485622Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.480625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data for classification\n",
    "if 'rrs_stack' in dir():\n",
    "    n_rows, n_cols, n_bands = rrs_stack.shape\n",
    "    rrs_2d = rrs_stack.reshape(-1, n_bands)\n",
    "    \n",
    "    print(f\"Original shape: {rrs_stack.shape}\")\n",
    "    print(f\"Reshaped for clustering: {rrs_2d.shape}\")\n",
    "    \n",
    "    # Create mask for valid pixels\n",
    "    valid_mask = np.sum(~np.isnan(rrs_2d), axis=1) > (n_bands * 0.8)\n",
    "    print(f\"Valid pixels: {valid_mask.sum():,} out of {len(valid_mask):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.488228Z",
     "iopub.status.busy": "2026-01-18T03:45:13.487943Z",
     "iopub.status.idle": "2026-01-18T03:45:13.496355Z",
     "shell.execute_reply": "2026-01-18T03:45:13.494826Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.488202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform K-means clustering\n",
    "if 'valid_mask' in dir() and valid_mask.sum() > 0:\n",
    "    rrs_valid = rrs_2d[valid_mask].copy()\n",
    "    \n",
    "    # Fill NaNs with band means\n",
    "    for i in range(rrs_valid.shape[1]):\n",
    "        band_mean = np.nanmean(rrs_valid[:, i])\n",
    "        rrs_valid[np.isnan(rrs_valid[:, i]), i] = band_mean\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    rrs_scaled = scaler.fit_transform(rrs_valid)\n",
    "    \n",
    "    # Run K-means with 4 clusters\n",
    "    n_clusters = 4\n",
    "    print(f\"Running K-means clustering with {n_clusters} clusters...\")\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    labels_valid = kmeans.fit_predict(rrs_scaled)\n",
    "    \n",
    "    print(f\"Clustering complete!\")\n",
    "    print(f\"\\nCluster sizes:\")\n",
    "    for i in range(n_clusters):\n",
    "        count = np.sum(labels_valid == i)\n",
    "        pct = 100 * count / len(labels_valid)\n",
    "        print(f\"  Cluster {i}: {count:,} pixels ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.497438Z",
     "iopub.status.busy": "2026-01-18T03:45:13.497173Z",
     "iopub.status.idle": "2026-01-18T03:45:13.502680Z",
     "shell.execute_reply": "2026-01-18T03:45:13.501316Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.497412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map labels back to image dimensions\n",
    "if 'labels_valid' in dir():\n",
    "    labels_image = np.full(n_rows * n_cols, np.nan)\n",
    "    labels_image[valid_mask] = labels_valid\n",
    "    labels_image = labels_image.reshape(n_rows, n_cols)\n",
    "    print(f\"Classification map shape: {labels_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.503893Z",
     "iopub.status.busy": "2026-01-18T03:45:13.503635Z",
     "iopub.status.idle": "2026-01-18T03:45:13.515271Z",
     "shell.execute_reply": "2026-01-18T03:45:13.513831Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.503868Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the classification\n",
    "if 'labels_image' in dir():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    wavelengths_sorted = sorted(wavelengths_rrs)\n",
    "    \n",
    "    def find_closest_idx(target_wl):\n",
    "        return np.argmin(np.abs(np.array(wavelengths_sorted) - target_wl))\n",
    "    \n",
    "    r_idx, g_idx, b_idx = find_closest_idx(650), find_closest_idx(550), find_closest_idx(480)\n",
    "    \n",
    "    # Create RGB composite\n",
    "    rgb = np.stack([rrs_stack[:, :, r_idx], rrs_stack[:, :, g_idx], rrs_stack[:, :, b_idx]], axis=-1)\n",
    "    rgb_norm = rgb.copy()\n",
    "    for i in range(3):\n",
    "        band = rgb_norm[:, :, i]\n",
    "        valid = ~np.isnan(band)\n",
    "        if valid.any():\n",
    "            p2, p98 = np.nanpercentile(band[valid], [2, 98])\n",
    "            band = np.clip((band - p2) / (p98 - p2), 0, 1)\n",
    "            rgb_norm[:, :, i] = band\n",
    "    rgb_norm = np.nan_to_num(rgb_norm, nan=0)\n",
    "    \n",
    "    axes[0].imshow(rgb_norm)\n",
    "    axes[0].set_title('Corrected RGB Composite (Rrs)', fontsize=14)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    cmap = plt.cm.get_cmap('tab10', n_clusters)\n",
    "    im = axes[1].imshow(labels_image, cmap=cmap, vmin=-0.5, vmax=n_clusters-0.5)\n",
    "    axes[1].set_title('Hyperspectral Classification (K-means)', fontsize=14)\n",
    "    axes[1].axis('off')\n",
    "    cbar = plt.colorbar(im, ax=axes[1], ticks=range(n_clusters), shrink=0.8)\n",
    "    cbar.ax.set_yticklabels([f'Class {i}' for i in range(n_clusters)])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.516542Z",
     "iopub.status.busy": "2026-01-18T03:45:13.516280Z",
     "iopub.status.idle": "2026-01-18T03:45:13.524572Z",
     "shell.execute_reply": "2026-01-18T03:45:13.523007Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.516518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot mean spectrum for each cluster\n",
    "if 'kmeans' in dir() and 'scaler' in dir():\n",
    "    centers_scaled = kmeans.cluster_centers_\n",
    "    centers = scaler.inverse_transform(centers_scaled)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    colors = plt.cm.tab10.colors\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        ax.plot(wavelengths_sorted, centers[i], label=f'Cluster {i}', color=colors[i], linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Wavelength (nm)', fontsize=12)\n",
    "    ax.set_ylabel('Remote Sensing Reflectance (Rrs)', fontsize=12)\n",
    "    ax.set_title('Mean Spectral Signature of Each Cluster', fontsize=14)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axvline(x=675, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.text(680, ax.get_ylim()[1]*0.9, 'Chl-a\\nabsorption', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nCluster Interpretation Guide:\")\n",
    "    print(\"- Highest reflectance = likely sand or bright substrate\")\n",
    "    print(\"- Lowest reflectance = likely deep water\")\n",
    "    print(\"- Absorption at 675nm = likely vegetation (seagrass/algae)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. The Hyperspectral Advantage: Comparison with Simulated Multispectral\n",
    "\n",
    "Now comes the key question: **Does having 426 bands actually help?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.526212Z",
     "iopub.status.busy": "2026-01-18T03:45:13.525829Z",
     "iopub.status.idle": "2026-01-18T03:45:13.534104Z",
     "shell.execute_reply": "2026-01-18T03:45:13.532856Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.526171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sentinel-2 band center wavelengths\n",
    "s2_wavelengths = {'B1': 443, 'B2': 490, 'B3': 560, 'B4': 665, 'B5': 705, \n",
    "                  'B6': 740, 'B7': 783, 'B8': 842, 'B8A': 865}\n",
    "\n",
    "if 'wavelengths_rrs' in dir():\n",
    "    wavelengths_sorted = sorted(wavelengths_rrs)\n",
    "    s2_indices = []\n",
    "    \n",
    "    print(\"Mapping Sentinel-2 bands to Tanager bands:\")\n",
    "    for band_name, wl in s2_wavelengths.items():\n",
    "        idx = np.argmin(np.abs(np.array(wavelengths_sorted) - wl))\n",
    "        actual_wl = wavelengths_sorted[idx]\n",
    "        s2_indices.append(idx)\n",
    "        print(f\"  {band_name} ({wl}nm) -> Index {idx} ({actual_wl:.0f}nm)\")\n",
    "    \n",
    "    print(f\"\\nSimulated multispectral: {len(s2_indices)} bands\")\n",
    "    print(f\"Original hyperspectral: {len(wavelengths_sorted)} bands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.535827Z",
     "iopub.status.busy": "2026-01-18T03:45:13.535553Z",
     "iopub.status.idle": "2026-01-18T03:45:13.545092Z",
     "shell.execute_reply": "2026-01-18T03:45:13.543625Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.535803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create and classify multispectral subset\n",
    "if 'rrs_stack' in dir() and 's2_indices' in dir():\n",
    "    rrs_multispectral = rrs_stack[:, :, s2_indices]\n",
    "    rrs_multi_2d = rrs_multispectral.reshape(-1, len(s2_indices))\n",
    "    rrs_multi_valid = rrs_multi_2d[valid_mask].copy()\n",
    "    \n",
    "    for i in range(rrs_multi_valid.shape[1]):\n",
    "        band_mean = np.nanmean(rrs_multi_valid[:, i])\n",
    "        rrs_multi_valid[np.isnan(rrs_multi_valid[:, i]), i] = band_mean\n",
    "    \n",
    "    scaler_multi = StandardScaler()\n",
    "    rrs_multi_scaled = scaler_multi.fit_transform(rrs_multi_valid)\n",
    "    \n",
    "    print(f\"Running K-means on multispectral data ({len(s2_indices)} bands)...\")\n",
    "    kmeans_multi = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    labels_multi_valid = kmeans_multi.fit_predict(rrs_multi_scaled)\n",
    "    \n",
    "    labels_multi_image = np.full(n_rows * n_cols, np.nan)\n",
    "    labels_multi_image[valid_mask] = labels_multi_valid\n",
    "    labels_multi_image = labels_multi_image.reshape(n_rows, n_cols)\n",
    "    print(\"Multispectral classification complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.546224Z",
     "iopub.status.busy": "2026-01-18T03:45:13.545937Z",
     "iopub.status.idle": "2026-01-18T03:45:13.553551Z",
     "shell.execute_reply": "2026-01-18T03:45:13.552029Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.546198Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compare classifications\n",
    "if 'labels_image' in dir() and 'labels_multi_image' in dir():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    axes[0].imshow(rgb_norm)\n",
    "    axes[0].set_title('RGB Reference', fontsize=14)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    cmap = plt.cm.get_cmap('tab10', n_clusters)\n",
    "    axes[1].imshow(labels_image, cmap=cmap, vmin=-0.5, vmax=n_clusters-0.5)\n",
    "    axes[1].set_title(f'Hyperspectral Classification\\n({len(wavelengths_sorted)} bands)', fontsize=14)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(labels_multi_image, cmap=cmap, vmin=-0.5, vmax=n_clusters-0.5)\n",
    "    axes[2].set_title(f'Multispectral Classification\\n({len(s2_indices)} bands)', fontsize=14)\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle('Hyperspectral vs Multispectral Benthic Classification', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-18T03:45:13.556470Z",
     "iopub.status.busy": "2026-01-18T03:45:13.556181Z",
     "iopub.status.idle": "2026-01-18T03:45:13.562488Z",
     "shell.execute_reply": "2026-01-18T03:45:13.561372Z",
     "shell.execute_reply.started": "2026-01-18T03:45:13.556444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quantify difference\n",
    "if 'labels_valid' in dir() and 'labels_multi_valid' in dir():\n",
    "    from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "    \n",
    "    ari = adjusted_rand_score(labels_valid, labels_multi_valid)\n",
    "    nmi = normalized_mutual_info_score(labels_valid, labels_multi_valid)\n",
    "    \n",
    "    print(\"Classification Similarity Metrics:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Adjusted Rand Index (ARI): {ari:.3f}\")\n",
    "    print(f\"Normalized Mutual Information (NMI): {nmi:.3f}\")\n",
    "    print(f\"\\nThe classifications agree {ari*100:.1f}% more than random chance.\")\n",
    "    \n",
    "    if ari < 0.7:\n",
    "        print(\"\\nThis substantial difference suggests hyperspectral data\")\n",
    "        print(\"captures information that multispectral sensors miss!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Summary and Conclusions\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "1. **Loaded and visualized** Planet Tanager hyperspectral imagery using HyperCoast\n",
    "2. **Explored spectral signatures** of different features interactively\n",
    "3. **Performed atmospheric correction** using Acolite\n",
    "4. **Extracted and interpreted** spectral signatures of benthic habitat types\n",
    "5. **Classified benthic habitats** using K-means clustering\n",
    "6. **Compared results** between hyperspectral (426 bands) and simulated multispectral (9 bands)\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "**Hyperspectral data provides:**\n",
    "- Detailed spectral information for finer discrimination\n",
    "- Detection of subtle absorption features (like chlorophyll at 675nm)\n",
    "- Better separation of spectrally similar materials\n",
    "\n",
    "**Atmospheric correction is essential** - the signal from water/seafloor is only 5-15% of what the sensor sees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data & Software Attribution\n",
    "\n",
    "**Tanager Data**: Tanager STAC Data, available at www.planet.com/data/stac - 2025 Planet Labs PBC. All Rights Reserved.\n",
    "\n",
    "**HyperCoast**: Liu, B., & Wu, Q. (2024). HyperCoast: A Python Package for Visualizing and Analyzing Hyperspectral Data in Coastal Environments. Journal of Open Source Software, 9(100), 7025. https://doi.org/10.21105/joss.07025\n",
    "\n",
    "**Acolite**: Vanhellemont, Q., & Ruddick, K. (2018). Atmospheric correction of metre-scale optical satellite data for inland and coastal water applications. Remote Sensing of Environment, 216, 586-597.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "edc",
   "name": "workbench-notebooks.m137",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
  },
  "kernelspec": {
   "display_name": "EEPS EDC (Local)",
   "language": "python",
   "name": "edc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
